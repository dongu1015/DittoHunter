# Standard Library
import os
import random
import time
import warnings
from io import BytesIO
import glob

# Third Party - Core
import numpy as np
import cv2
from PIL import Image

# Third Party - ML/DL
import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import random
import time
from PIL import Image
from torchvision import models, transforms
from torch_geometric.data import Data, DataLoader
from torch_geometric.nn import GATv2Conv, global_mean_pool
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score
import optuna
import warnings

warnings.filterwarnings('ignore')

# PyTorch ë””ë°”ì´ìŠ¤ ì„¤ì •
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"ğŸ”§ ì‚¬ìš© ë””ë°”ì´ìŠ¤: {device}")

# CNN-GAT ëª¨ë¸ í´ë˜ìŠ¤ë“¤
class CNNExtractor(nn.Module):
    """CNN íŠ¹ì§• ì¶”ì¶œê¸° (MobileNetV2 ê¸°ë°˜)"""
    def __init__(self, output_dim=64):
        super().__init__()
        # MobileNetV2 ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸ ì‚¬ìš©
        base = models.mobilenet_v2(weights=models.MobileNet_V2_Weights.IMAGENET1K_V1).features
        self.cnn = nn.Sequential(*list(base.children()))
        self.pool = nn.AdaptiveAvgPool2d((1, 1))
        self.proj = nn.Linear(1280, output_dim)
        self.dropout = nn.Dropout(0.2)

    def forward(self, x):
        x = self.pool(self.cnn(x)).squeeze(-1).squeeze(-1)
        x = self.dropout(x)
        return self.proj(x)

class GATNet(nn.Module):
    """Graph Attention Network ë”¥í˜ì´í¬ ê²€ì¶œê¸°"""
    def __init__(self, in_channels=64, hidden_channels=64, out_channels=2, heads=4, dropout=0.2):
        super().__init__()
        self.gat1 = GATv2Conv(in_channels, hidden_channels, heads=heads, dropout=dropout, add_self_loops=False)
        self.gat2 = GATv2Conv(hidden_channels * heads, hidden_channels, heads=1, dropout=dropout, add_self_loops=False)
        self.mlp = nn.Sequential(
            nn.Linear(hidden_channels, 64),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(64, out_channels)
        )

    def forward(self, x, edge_index, batch):
        x, _ = self.gat1(x, edge_index, return_attention_weights=True)
        x = F.elu(x)
        x, _ = self.gat2(x, edge_index, return_attention_weights=True)
        x = F.elu(x)
        x = global_mean_pool(x, batch)
        return self.mlp(x)

class SimpleDeepfakeDetectorTrainer:
    def __init__(self, data_dir="data"):
        """ë”¥í˜ì´í¬ ê²€ì¶œ ëª¨ë¸ í•™ìŠµê¸° ì´ˆê¸°í™” (ë¡œì»¬ íŒŒì¼ ê¸°ë°˜)"""
        self.data_dir = data_dir
        self.fake_dir = os.path.join(data_dir, "fake")
        self.real_dir = os.path.join(data_dir, "real")
        
        # ë°ì´í„° ë””ë ‰í† ë¦¬ í™•ì¸
        if not os.path.exists(self.fake_dir):
            os.makedirs(self.fake_dir, exist_ok=True)
            print(f"ğŸ“ Created fake images directory: {self.fake_dir}")
        if not os.path.exists(self.real_dir):
            os.makedirs(self.real_dir, exist_ok=True)
            print(f"ğŸ“ Created real images directory: {self.real_dir}")
        
        # CNN ë³€í™˜ê¸° ì„¤ì •
        self.transform = transforms.Compose([
            transforms.Resize((256, 256)),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # ImageNet í‘œì¤€í™”
        ])
        
        # CNN íŠ¹ì§• ì¶”ì¶œê¸° ì´ˆê¸°í™”
        self.cnn_extractor = CNNExtractor().to(device).eval()
        print("ğŸ§  CNN íŠ¹ì§• ì¶”ì¶œê¸° ì´ˆê¸°í™” ì™„ë£Œ")

    def fft_preprocess(self, img, size=(256, 256)):
        """FFT ì „ì²˜ë¦¬ë¡œ ì£¼íŒŒìˆ˜ ë„ë©”ì¸ íŠ¹ì§• ì¶”ì¶œ"""
        if isinstance(img, Image.Image):
            img = np.array(img)
        
        img = cv2.resize(img, size)
        fft_channels = []
        
        for i in range(3):  # RGB ê° ì±„ë„
            fft = np.fft.fftshift(np.fft.fft2(img[:, :, i]))
            magnitude = 20 * np.log(np.abs(fft) + 1e-8)
            fft_channels.append(magnitude)
        
        fft_img = np.stack(fft_channels, axis=2)
        return cv2.normalize(fft_img, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)

    def simple_region_detection(self, img):
        """ê°„ë‹¨í•œ ì§€ì—­ ê°ì§€ (ì–¼êµ´/ë°°ê²½)"""
        h, w = img.shape[:2]
        
        # OpenCV ì–¼êµ´ ê²€ì¶œê¸° ì‚¬ìš©
        face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        faces = face_cascade.detectMultiScale(gray, 1.1, 4)
        
        face_mask = np.zeros((h, w), np.uint8)
        for (x, y, w_face, h_face) in faces:
            cv2.rectangle(face_mask, (x, y), (x + w_face, y + h_face), 255, -1)
        
        # ë°°ê²½ ë§ˆìŠ¤í¬ (ì–¼êµ´ì´ ì•„ë‹Œ ë¶€ë¶„)
        bg_mask = np.ones((h, w), np.uint8) * 255
        bg_mask[face_mask == 255] = 0
        
        return face_mask, bg_mask

    def split_into_patches(self, img, patch_size=(32, 32)):
        """ì´ë¯¸ì§€ë¥¼ íŒ¨ì¹˜ë¡œ ë¶„í• """
        img_pil = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
        fft_img = self.fft_preprocess(img_pil.resize((256, 256)))
        
        patches = []
        for y in range(0, 256, patch_size[0]):
            for x in range(0, 256, patch_size[1]):
                patch = fft_img[y:y+patch_size[0], x:x+patch_size[1]]
                if patch.shape[:2] == patch_size:
                    patches.append(patch)
        
        return patches, patch_size[0]

    def create_graph_from_image(self, img, label):
        """ì´ë¯¸ì§€ì—ì„œ ê·¸ë˜í”„ ë°ì´í„° ìƒì„± (ê°„ì†Œí™” ë²„ì „)"""
        try:
            # 1. ì§€ì—­ ë§ˆìŠ¤í¬ ìƒì„± (ê°„ì†Œí™”)
            face_mask, bg_mask = self.simple_region_detection(img)
            
            # 2. íŒ¨ì¹˜ ë¶„í• 
            patches, patch_size = self.split_into_patches(img)
            rows, cols = 256 // patch_size, 256 // patch_size
            
            if len(patches) != rows * cols:
                return None
            
            # 3. íŒ¨ì¹˜ë³„ íŠ¹ì§• ì¶”ì¶œ
            features = []
            for patch in patches:
                patch_tensor = self.transform(Image.fromarray(patch)).unsqueeze(0).to(device)
                with torch.no_grad():
                    feat = self.cnn_extractor(patch_tensor).squeeze(0).cpu()
                features.append(feat)
            
            # 4. ê°„ë‹¨í•œ ê·¸ë˜í”„ ì—£ì§€ ìƒì„± (4-ì—°ê²° ê·¸ë¦¬ë“œ)
            edge_index = []
            
            for i in range(rows):
                for j in range(cols):
                    current_idx = i * cols + j
                    
                    # 4-ì—°ê²° ê·¸ë¦¬ë“œ
                    for di, dj in [(-1, 0), (1, 0), (0, -1), (0, 1)]:
                        ni, nj = i + di, j + dj
                        if 0 <= ni < rows and 0 <= nj < cols:
                            neighbor_idx = ni * cols + nj
                            edge_index.append([current_idx, neighbor_idx])
            
            # 5. ê·¸ë˜í”„ ë°ì´í„° ìƒì„±
            if not edge_index:
                # ì—£ì§€ê°€ ì—†ìœ¼ë©´ ìê¸° ìì‹ ê³¼ ì—°ê²°
                edge_index = [[i, i] for i in range(len(features))]
            
            graph_data = Data(
                x=torch.stack(features),
                edge_index=torch.tensor(edge_index, dtype=torch.long).T.contiguous(),
                y=torch.tensor(label, dtype=torch.long)
            )
            
            return graph_data
            
        except Exception as e:
            print(f"âŒ ê·¸ë˜í”„ ìƒì„± ì˜¤ë¥˜: {e}")
            return None

    def apply_data_augmentation(self, fake_graphs, real_graphs, augmentation_factor=2):
        """ë°ì´í„° ì¦ê°•ìœ¼ë¡œ í•™ìŠµ ë°ì´í„° í™•ì¥"""
        print(f"ğŸ”„ ë°ì´í„° ì¦ê°• ì‹œì‘ (ì¦ê°• ë°°ìˆ˜: {augmentation_factor}x)")
        
        original_fake_count = len(fake_graphs)
        original_real_count = len(real_graphs)
        
        # Fake ë°ì´í„° ì¦ê°•
        augmented_fake = []
        for _ in range(augmentation_factor - 1):  # ì›ë³¸ ì œì™¸í•˜ê³  ì¶”ê°€ ìƒì„±
            for graph in fake_graphs:
                # ê·¸ë˜í”„ ë°ì´í„°ì—ì„œ ì›ë³¸ íŠ¹ì§• ì¶”ì¶œì€ ì–´ë ¤ìš°ë¯€ë¡œ, 
                # ë™ì¼í•œ ê·¸ë˜í”„ì— ì•½ê°„ì˜ ë…¸ì´ì¦ˆ ì¶”ê°€
                augmented_graph = Data(
                    x=graph.x + torch.randn_like(graph.x) * 0.01,  # ì‘ì€ ë…¸ì´ì¦ˆ ì¶”ê°€
                    edge_index=graph.edge_index,
                    y=graph.y
                )
                augmented_fake.append(augmented_graph)
        
        # Real ë°ì´í„° ì¦ê°•
        augmented_real = []
        for _ in range(augmentation_factor - 1):
            for graph in real_graphs:
                augmented_graph = Data(
                    x=graph.x + torch.randn_like(graph.x) * 0.01,
                    edge_index=graph.edge_index,
                    y=graph.y
                )
                augmented_real.append(augmented_graph)
        
        # ì¦ê°•ëœ ë°ì´í„° ì¶”ê°€
        fake_graphs.extend(augmented_fake)
        real_graphs.extend(augmented_real)
        
        print(f"âœ… ë°ì´í„° ì¦ê°• ì™„ë£Œ!")
        print(f"   Fake: {original_fake_count:,} â†’ {len(fake_graphs):,}ê°œ (+{len(augmented_fake):,})")
        print(f"   Real: {original_real_count:,} â†’ {len(real_graphs):,}ê°œ (+{len(augmented_real):,})")
        
        return fake_graphs, real_graphs

    def load_training_data(self, num_samples=None):
        """ë¡œì»¬ ë””ë ‰í† ë¦¬ì—ì„œ í•™ìŠµ ë°ì´í„° ë¡œë“œ"""
        
        # ë¡œì»¬ íŒŒì¼ ê²½ë¡œì—ì„œ ì´ë¯¸ì§€ ìˆ˜ì§‘
        fake_files = []
        real_files = []
        
        # fake ì´ë¯¸ì§€ ìˆ˜ì§‘
        fake_extensions = ['*.jpg', '*.jpeg', '*.png', '*.bmp', '*.tiff']
        for ext in fake_extensions:
            fake_files.extend(glob.glob(os.path.join(self.fake_dir, ext)))
            fake_files.extend(glob.glob(os.path.join(self.fake_dir, ext.upper())))
        
        # real ì´ë¯¸ì§€ ìˆ˜ì§‘
        real_extensions = ['*.jpg', '*.jpeg', '*.png', '*.bmp', '*.tiff']
        for ext in real_extensions:
            real_files.extend(glob.glob(os.path.join(self.real_dir, ext)))
            real_files.extend(glob.glob(os.path.join(self.real_dir, ext.upper())))
        
        print(f"ğŸ“Š ë°œê²¬ëœ ì´ë¯¸ì§€:")
        print(f"   Fake: {len(fake_files):,}ê°œ")
        print(f"   Real: {len(real_files):,}ê°œ")
        
        if len(fake_files) < 5 or len(real_files) < 5:
            print(f"âš ï¸  Warning: í•™ìŠµì— í•„ìš”í•œ ìµœì†Œ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
            print(f"   ê° í´ë”ì— ìµœì†Œ 5ê°œ ì´ìƒì˜ ì´ë¯¸ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
            print(f"   Fake í´ë”: {self.fake_dir}")
            print(f"   Real í´ë”: {self.real_dir}")
            return [], []
        
        # ìƒ˜í”Œ ìˆ˜ ì œí•œ ì ìš©
        if num_samples is not None:
            fake_samples = min(num_samples // 2, len(fake_files))
            real_samples = min(num_samples // 2, len(real_files))
            fake_files = random.sample(fake_files, fake_samples)
            real_files = random.sample(real_files, real_samples)
            print(f"ğŸ¯ ì œí•œëœ ìƒ˜í”Œ ì‚¬ìš©:")
            print(f"   Fake: {len(fake_files):,}ê°œ")
            print(f"   Real: {len(real_files):,}ê°œ")
        
        fake_graphs = []
        real_graphs = []
        
        success_count = 0
        total_attempts = len(fake_files) + len(real_files)
        
        print(f"ğŸ“š í•™ìŠµ ë°ì´í„° ìƒì„± ì‹œì‘: {total_attempts:,}ê°œ ì²˜ë¦¬ ì˜ˆì •")
        
        # Fake ì´ë¯¸ì§€ ì²˜ë¦¬
        print("ğŸ”´ Fake ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘...")
        for i, file_path in enumerate(fake_files):
            if i % 50 == 0:
                print(f"Fake ì§„í–‰ë¥ : {i+1:,}/{len(fake_files):,} ({(i+1)/len(fake_files)*100:.1f}%)")
            
            try:
                # ì´ë¯¸ì§€ ë¡œë“œ
                img = cv2.imread(file_path)
                if img is None:
                    continue
                
                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
                img = Image.fromarray(img)
                
                # ê·¸ë˜í”„ ë°ì´í„° ìƒì„±
                graph = self.create_graph_from_image(img, label=0)  # fake = 0
                if graph is not None:
                    fake_graphs.append(graph)
                    success_count += 1
                    
            except Exception as e:
                continue
        
        # Real ì´ë¯¸ì§€ ì²˜ë¦¬
        print("ğŸŸ¢ Real ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘...")
        for i, file_path in enumerate(real_files):
            if i % 50 == 0:
                print(f"Real ì§„í–‰ë¥ : {i+1:,}/{len(real_files):,} ({(i+1)/len(real_files)*100:.1f}%)")
            
            try:
                # ì´ë¯¸ì§€ ë¡œë“œ
                img = cv2.imread(file_path)
                if img is None:
                    continue
                
                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
                img = Image.fromarray(img)
                
                # ê·¸ë˜í”„ ë°ì´í„° ìƒì„±
                graph = self.create_graph_from_image(img, label=1)  # real = 1
                if graph is not None:
                    real_graphs.append(graph)
                    success_count += 1
                    
            except Exception as e:
                continue
        
        print(f"\nâœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ!")
        print(f"   ì²˜ë¦¬ëœ ì´ë¯¸ì§€: {total_attempts:,}ê°œ")
        print(f"   ì„±ê³µí•œ ê·¸ë˜í”„: {success_count:,}ê°œ")
        print(f"   Fake ê·¸ë˜í”„: {len(fake_graphs):,}ê°œ")
        print(f"   Real ê·¸ë˜í”„: {len(real_graphs):,}ê°œ")
        print(f"   ì„±ê³µë¥ : {success_count/total_attempts*100:.1f}%")
        
        return fake_graphs, real_graphs

    def optimize_hyperparameters(self, train_loader, val_loader, n_trials=10):
        """Optunaë¥¼ ì‚¬ìš©í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”"""
        print(f"ğŸ”§ í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ì‹œì‘ ({n_trials}íšŒ ì‹œë„)")
        
        def objective(trial):
            # í•˜ì´í¼íŒŒë¼ë¯¸í„° í›„ë³´
            hidden_channels = trial.suggest_categorical("hidden_channels", [32, 64, 128])
            heads = trial.suggest_categorical("heads", [1, 2, 4])
            dropout = trial.suggest_float("dropout", 0.0, 0.4)
            lr = trial.suggest_float("lr", 1e-4, 1e-2, log=True)
            weight_decay = trial.suggest_float("weight_decay", 1e-6, 1e-3, log=True)
            
            # ëª¨ë¸ ìƒì„±
            model = GATNet(
                in_channels=64,
                hidden_channels=hidden_channels,
                out_channels=2,
                heads=heads,
                dropout=dropout
            ).to(device)
            
            optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)
            criterion = nn.CrossEntropyLoss()
            
            # ë¹ ë¥¸ í•™ìŠµ (3 ì—í¬í¬)
            model.train()
            for epoch in range(3):
                for batch in train_loader:
                    batch = batch.to(device)
                    out = model(batch.x, batch.edge_index, batch.batch)
                    loss = criterion(out, batch.y)
                    optimizer.zero_grad()
                    loss.backward()
                    optimizer.step()
            
            # ê²€ì¦
            model.eval()
            correct = total = 0
            with torch.no_grad():
                for batch in val_loader:
                    batch = batch.to(device)
                    out = model(batch.x, batch.edge_index, batch.batch)
                    pred = out.argmax(dim=1)
                    correct += (pred == batch.y).sum().item()
                    total += batch.y.size(0)
            
            accuracy = correct / total
            return accuracy
        
        study = optuna.create_study(direction="maximize")
        study.optimize(objective, n_trials=n_trials)
        
        print(f"ğŸ¯ ìµœì í™” ì™„ë£Œ! ìµœê³  ì •í™•ë„: {study.best_value:.4f}")
        print(f"ğŸ“‹ ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„°:")
        for key, value in study.best_params.items():
            print(f"   {key}: {value}")
        
        return study.best_params

    def train_model(self, num_samples=None, epochs=50, use_optuna=True, use_data_augmentation=True, test_size=0.15):
        """ë”¥í˜ì´í¬ ê²€ì¶œ ëª¨ë¸ í•™ìŠµ (ì „ì²´ ë°ì´í„°ì…‹ + ë°ì´í„° ì¦ê°•)"""
        print("ğŸš€ ë”¥í˜ì´í¬ ê²€ì¶œ ëª¨ë¸ í•™ìŠµ ì‹œì‘! (ì „ì²´ ë°ì´í„°ì…‹)")
        
        # 1. ë°ì´í„° ë¡œë“œ
        fake_graphs, real_graphs = self.load_training_data(num_samples)
        
        # 2. ë°ì´í„° ì¦ê°• ì ìš©
        if use_data_augmentation:
            fake_graphs, real_graphs = self.apply_data_augmentation(fake_graphs, real_graphs, augmentation_factor=3)
        
        # 3. ë°ì´í„° ë¶„í• 
        fake_train, fake_test = train_test_split(fake_graphs, test_size=test_size, random_state=42)
        real_train, real_test = train_test_split(real_graphs, test_size=test_size, random_state=42)
        
        train_data = fake_train + real_train
        test_data = fake_test + real_test
        
        # ë°ì´í„° ì…”í”Œ
        random.shuffle(train_data)
        random.shuffle(test_data)
        
        # ê²€ì¦ ë°ì´í„° ë¶„í•  (í•™ìŠµ ë°ì´í„°ì˜ 15%)
        val_size = max(50, len(train_data) // 7)  # ìµœì†Œ 50ê°œ, ìµœëŒ€ ì „ì²´ì˜ 1/7
        val_data = train_data[:val_size]
        train_data = train_data[val_size:]
        
        # ë°ì´í„°ë¡œë” ìƒì„± (ë°°ì¹˜ í¬ê¸° ì¦ê°€)
        batch_size = min(8, len(train_data) // 10)  # ì ì‘ì  ë°°ì¹˜ í¬ê¸°
        train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)
        val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)
        test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)
        
        print(f"\nğŸ“Š ìµœì¢… ë°ì´í„° ë¶„í• :")
        print(f"   í•™ìŠµ: {len(train_data):,}ê°œ")
        print(f"   ê²€ì¦: {len(val_data):,}ê°œ") 
        print(f"   í…ŒìŠ¤íŠ¸: {len(test_data):,}ê°œ")
        print(f"   ë°°ì¹˜ í¬ê¸°: {batch_size}")
        
        # 4. í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”
        if use_optuna and len(train_data) > 100:
            print(f"\nğŸ”§ í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ({len(train_data):,}ê°œ í•™ìŠµ ë°ì´í„°)")
            best_params = self.optimize_hyperparameters(train_loader, val_loader, n_trials=20)
        else:
            best_params = {
                "hidden_channels": 128,
                "heads": 4,
                "dropout": 0.15,
                "lr": 0.002,
                "weight_decay": 1e-5
            }
            print("ğŸ”§ ê¸°ë³¸ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì‚¬ìš© (ëŒ€ìš©ëŸ‰ ë°ì´í„°ì— ìµœì í™”)")
        
        # 5. ìµœì¢… ëª¨ë¸ í•™ìŠµ
        print(f"\nğŸ¯ ìµœì¢… ëª¨ë¸ í•™ìŠµ ({epochs} ì—í¬í¬, {len(train_data):,}ê°œ í•™ìŠµ ë°ì´í„°)")
        
        model = GATNet(
            in_channels=64,
            hidden_channels=best_params["hidden_channels"],
            out_channels=2,
            heads=best_params["heads"],
            dropout=best_params["dropout"]
        ).to(device)
        
        optimizer = torch.optim.AdamW(
            model.parameters(),
            lr=best_params["lr"],
            weight_decay=best_params["weight_decay"]
        )
        criterion = nn.CrossEntropyLoss()
        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=8, factor=0.5)
        
        best_acc = 0.0
        patience_counter = 0
        max_patience = 15  # ëŒ€ìš©ëŸ‰ ë°ì´í„°ì—ì„œëŠ” ë” ë§ì€ patience
        
        train_start_time = time.time()
        
        for epoch in range(epochs):
            # í•™ìŠµ
            model.train()
            total_loss = 0
            batch_count = 0
            
            for batch in train_loader:
                batch = batch.to(device)
                out = model(batch.x, batch.edge_index, batch.batch)
                loss = criterion(out, batch.y)
                optimizer.zero_grad()
                loss.backward()
                
                # ê·¸ë˜ë””ì–¸íŠ¸ í´ë¦¬í•‘ (ì•ˆì •ì„± í–¥ìƒ)
                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
                
                optimizer.step()
                total_loss += loss.item()
                batch_count += 1
            
            avg_loss = total_loss / batch_count if batch_count > 0 else 0
            
            # ê²€ì¦
            model.eval()
            val_correct = val_total = 0
            val_loss = 0
            
            with torch.no_grad():
                for batch in val_loader:
                    batch = batch.to(device)
                    out = model(batch.x, batch.edge_index, batch.batch)
                    loss = criterion(out, batch.y)
                    val_loss += loss.item()
                    
                    pred = out.argmax(dim=1)
                    val_correct += (pred == batch.y).sum().item()
                    val_total += batch.y.size(0)
            
            val_acc = val_correct / val_total if val_total > 0 else 0
            scheduler.step(val_acc)
            
            # ìµœê³  ëª¨ë¸ ì €ì¥
            if val_acc > best_acc:
                best_acc = val_acc
                torch.save({
                    'model_state_dict': model.state_dict(),
                    'hyperparameters': best_params,
                    'epoch': epoch,
                    'accuracy': best_acc,
                    'training_samples': len(train_data)
                }, "best_deepfake_detector_full.pth")
                patience_counter = 0
            else:
                patience_counter += 1
            
            # ì¡°ê¸° ì¢…ë£Œ
            if patience_counter >= max_patience:
                print(f"ğŸ’¤ ì¡°ê¸° ì¢…ë£Œ (patience: {max_patience})")
                break
            
            # ì§„í–‰ ìƒí™© ì¶œë ¥ (5 ì—í¬í¬ë§ˆë‹¤ ë˜ëŠ” ì²˜ìŒ/ë§ˆì§€ë§‰)
            if epoch % 5 == 0 or epoch == epochs - 1 or epoch < 3:
                elapsed = time.time() - train_start_time
                current_lr = optimizer.param_groups[0]['lr']
                print(f"Epoch {epoch:3d} | Loss: {avg_loss:.4f} | Val Acc: {val_acc:.4f} | "
                      f"Best: {best_acc:.4f} | LR: {current_lr:.2e} | Time: {elapsed:.1f}s")
        
        # 6. ìµœì¢… í‰ê°€
        print(f"\nğŸ“Š ìµœì¢… í‰ê°€ ({len(test_data):,}ê°œ í…ŒìŠ¤íŠ¸ ë°ì´í„°)")
        checkpoint = torch.load("best_deepfake_detector_full.pth")
        model.load_state_dict(checkpoint['model_state_dict'])
        
        # í…ŒìŠ¤íŠ¸ ë°ì´í„° í‰ê°€
        model.eval()
        y_true, y_pred, y_prob = [], [], []
        
        with torch.no_grad():
            for batch in test_loader:
                batch = batch.to(device)
                out = model(batch.x, batch.edge_index, batch.batch)
                prob = F.softmax(out, dim=1)
                pred = out.argmax(dim=1)
                
                y_true.extend(batch.y.cpu().tolist())
                y_pred.extend(pred.cpu().tolist())
                y_prob.extend(prob[:, 1].cpu().tolist())  # Real í´ë˜ìŠ¤ í™•ë¥ 
        
        # ì„±ëŠ¥ ì§€í‘œ ì¶œë ¥
        test_acc = sum(1 for i in range(len(y_true)) if y_true[i] == y_pred[i]) / len(y_true)
        
        try:
            auc_score = roc_auc_score(y_true, y_prob)
        except:
            auc_score = 0.0
        
        total_time = time.time() - train_start_time
        
        print(f"\nğŸ‰ í•™ìŠµ ì™„ë£Œ!")
        print(f"   í•™ìŠµ ë°ì´í„°: {len(train_data):,}ê°œ")
        print(f"   ìµœê³  ê²€ì¦ ì •í™•ë„: {best_acc:.4f}")
        print(f"   í…ŒìŠ¤íŠ¸ ì •í™•ë„: {test_acc:.4f}")
        print(f"   AUC ì ìˆ˜: {auc_score:.4f}")
        print(f"   ì´ í•™ìŠµ ì‹œê°„: {total_time:.1f}ì´ˆ ({total_time/60:.1f}ë¶„)")
        print(f"   í‰ê·  ì—í¬í¬ ì‹œê°„: {total_time/epoch:.1f}ì´ˆ")
        
        print(f"\nğŸ“‹ ë¶„ë¥˜ ë³´ê³ ì„œ:")
        print(classification_report(y_true, y_pred, target_names=["Fake", "Real"], digits=4))
        
        print(f"\nğŸ§© í˜¼ë™ í–‰ë ¬:")
        cm = confusion_matrix(y_true, y_pred)
        print(cm)
        
        # í´ë˜ìŠ¤ë³„ ì •í™•ë„
        fake_acc = cm[0,0] / (cm[0,0] + cm[0,1]) if (cm[0,0] + cm[0,1]) > 0 else 0
        real_acc = cm[1,1] / (cm[1,0] + cm[1,1]) if (cm[1,0] + cm[1,1]) > 0 else 0
        
        print(f"\nğŸ¯ í´ë˜ìŠ¤ë³„ ì •í™•ë„:")
        print(f"   Fake ê²€ì¶œ ì •í™•ë„: {fake_acc:.4f}")
        print(f"   Real ê²€ì¶œ ì •í™•ë„: {real_acc:.4f}")
        
        return model, best_acc, test_acc, auc_score

    def close(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        print("âœ… í•™ìŠµ ì™„ë£Œ - ë¦¬ì†ŒìŠ¤ ì •ë¦¬")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("=== ë”¥í˜ì´í¬ ê²€ì¶œ CNN-GAT ëª¨ë¸ í•™ìŠµê¸° (ë¡œì»¬ íŒŒì¼ ê¸°ë°˜) ===")
    
    trainer = SimpleDeepfakeDetectorTrainer(data_dir="data")
    
    try:
        # í•™ìŠµ ì„¤ì • (ì „ì²´ ë°ì´í„°ì…‹ ì‚¬ìš©)
        num_samples = None  # Noneì´ë©´ ì „ì²´ ë°ì´í„°ì…‹ ì‚¬ìš©
        epochs = 50         # ë” ë§ì€ ì—í¬í¬
        use_optuna = True   # í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ì‚¬ìš©
        use_data_augmentation = True  # ë°ì´í„° ì¦ê°• ì‚¬ìš©
        
        print(f"ğŸ“‹ í•™ìŠµ ì„¤ì •:")
        print(f"   ìƒ˜í”Œ ìˆ˜: {'ì „ì²´ ë°ì´í„°ì…‹' if num_samples is None else num_samples}")
        print(f"   ì—í¬í¬: {epochs}")
        print(f"   í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”: {use_optuna}")
        print(f"   ë°ì´í„° ì¦ê°•: {use_data_augmentation}")
        
        # ëª¨ë¸ í•™ìŠµ ì‹¤í–‰
        model, best_val_acc, test_acc, auc_score = trainer.train_model(
            num_samples=num_samples,
            epochs=epochs,
            use_optuna=use_optuna,
            use_data_augmentation=use_data_augmentation
        )
        
        print(f"\nğŸ† ìµœì¢… ê²°ê³¼:")
        print(f"   ê²€ì¦ ì •í™•ë„: {best_val_acc:.4f}")
        print(f"   í…ŒìŠ¤íŠ¸ ì •í™•ë„: {test_acc:.4f}")
        print(f"   AUC ì ìˆ˜: {auc_score:.4f}")
        print(f"   ëª¨ë¸ ì €ì¥: best_deepfake_detector.pth")
        
    except Exception as e:
        print(f"âŒ í•™ìŠµ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
    
    finally:
        trainer.close()

if __name__ == "__main__":
    main()
